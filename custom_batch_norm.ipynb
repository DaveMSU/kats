{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5de119-d09a-41d7-9e95-5deac33f5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "N = 1024 * 16\n",
    "VAL_SIZE = 512\n",
    "TRAIN_SIZE = N - VAL_SIZE\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "class CustomBatchNorm(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_features: int,\n",
    "            eps: float = 1e-05,\n",
    "            momentum: tp.Optional[float] = 0.1,\n",
    "            affine: bool = True,\n",
    "            track_running_stats: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._num_features: int = num_features\n",
    "        self._eps: float = eps\n",
    "        self._momentum: float = momentum\n",
    "        self._params: tp.Dict[str, torch.nn.Parameter] = torch.nn.ParameterDict(\n",
    "            {\n",
    "                \"weights\": torch.nn.Parameter(\n",
    "                    torch.ones(num_features),\n",
    "                    requires_grad=affine,\n",
    "                ),\n",
    "                \"bias\": torch.nn.Parameter(\n",
    "                    torch.zeros(num_features),\n",
    "                    requires_grad=affine\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        self._track_running_stats: bool = track_running_stats\n",
    "\n",
    "        # It is a torch.nn.ParameterDict to prevent \"ValueError: Expected all\n",
    "        # ... tensors to be on the same device...\"\n",
    "        # There are torch.nn.Parameter to prevent a \"RuntimeError: a leaf Variable that\n",
    "        # ...  requires grad is being used in an in-place operation.\"\n",
    "        self._running_stats: tp.Optional[\n",
    "            tp.Dict[\n",
    "                str,\n",
    "                tp.Union[torch.Tensor, int]\n",
    "            ]\n",
    "        ] = torch.nn.ParameterDict(  # to prevent \"Expected all tensors to be on the same device...\"\n",
    "            {\n",
    "                \"mean\": torch.nn.Parameter(torch.zeros(num_features), requires_grad=False),\n",
    "                \"var\": torch.nn.Parameter(torch.zeros(num_features), requires_grad=False),\n",
    "                \"count\": 0,\n",
    "            } if track_running_stats else None\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_dim_order: tp.Tuple[int] = tuple(range(x.ndim))\n",
    "        dims_to_be_reduced: tp.Tuple[int] = x_dim_order[:1] + x_dim_order[2:]\n",
    "        batch_mean: torch.Tensor = x.mean(\n",
    "            dim=dims_to_be_reduced,\n",
    "            keepdim=True,\n",
    "        )\n",
    "        batch_var: torch.Tensor = x.var(\n",
    "            dim=dims_to_be_reduced,\n",
    "            correction=0,\n",
    "            keepdim=True,\n",
    "        )\n",
    "        if self.training and self._track_running_stats:\n",
    "            correction: float = x.shape[0] / max(x.shape[0] - 1, 1)\n",
    "            beta: float\n",
    "            if self._momentum is None:\n",
    "                beta = x.shape[0] / (self._running_stats[\"count\"] + x.shape[0])\n",
    "            else:\n",
    "                beta = self._momentum\n",
    "            self._running_stats[\"mean\"].add_((beta * (batch_mean.view(-1) - self._running_stats[\"mean\"])))\n",
    "            self._running_stats[\"var\"].add_((beta * (correction * batch_var.view(-1) - self._running_stats[\"var\"])))\n",
    "            self._running_stats[\"count\"] += x.shape[0]\n",
    "\n",
    "        dims_to_be_unreduced = (1, -1) + (1,) * (x.ndim - 2)\n",
    "        shift: torch.Tensor\n",
    "        scale: torch.Tensor\n",
    "        if self.training or (not self._track_running_stats):\n",
    "            shift, scale = batch_mean, (batch_var + self._eps) ** 0.5\n",
    "        else:\n",
    "            shift = self._running_stats[\"mean\"].view(dims_to_be_unreduced)\n",
    "            scale = (self._running_stats[\"var\"].view(dims_to_be_unreduced) + self._eps) ** 0.5\n",
    "\n",
    "        x_normed: torch.Tensor = (x - shift) / scale\n",
    "        weights = self._params[\"weights\"].view(dims_to_be_unreduced)\n",
    "        bias = self._params[\"bias\"].view(dims_to_be_unreduced)\n",
    "        return x_normed * weights + bias\n",
    "\n",
    "\n",
    "mnist = MNIST(\"./\", download=True)\n",
    "X: torch.Tensor = mnist.data.view(-1, 1, 28, 28)[:N] / 255.\n",
    "y: torch.Tensor = mnist.targets[:N]\n",
    "\n",
    "X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "X_val, y_val = X[TRAIN_SIZE:], y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1009f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device: torch.device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "net: torch.nn.Module = torch.nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            (\n",
    "                'bn_test_0',\n",
    "                # torch.nn.BatchNorm2d(\n",
    "                CustomBatchNorm(\n",
    "                    num_features=1,\n",
    "                    eps=0.00001,\n",
    "                    momentum=0.1,\n",
    "                    affine=True,\n",
    "                    track_running_stats=True,\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                'conv_0',\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=1,\n",
    "                    out_channels=3,\n",
    "                    kernel_size=(3, 3),\n",
    "                    stride=(1, 1),\n",
    "                    padding=(0, 0),\n",
    "                    dilation=(1, 1),\n",
    "                    groups=1,\n",
    "                    bias=True,\n",
    "                )\n",
    "            ),\n",
    "            ('bn_test_1', CustomBatchNorm(3)),\n",
    "            # ('bn_test_1', torch.nn.BatchNorm2d(3)),\n",
    "            (\n",
    "                'act_1',\n",
    "                torch.nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            (\n",
    "                'pooling_2',\n",
    "                torch.nn.MaxPool2d(\n",
    "                    kernel_size=(4, 4),\n",
    "                    stride=(4, 4),\n",
    "                    padding=(0, 0),\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                'flatten_3',\n",
    "                Flatten()\n",
    "            ),\n",
    "            (\n",
    "                'fc_4',\n",
    "                torch.nn.Linear(\n",
    "                    in_features=3*6*6,\n",
    "                    out_features=10,\n",
    "                    bias=True,\n",
    "                )\n",
    "            ),\n",
    "            ('bn_test_2', CustomBatchNorm(10)),\n",
    "            # ('bn_test_2', torch.nn.BatchNorm1d(10)),\n",
    "            (\n",
    "                'act_5',\n",
    "                torch.nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            (\n",
    "                'fc_6',\n",
    "                torch.nn.Linear(10, 10)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ").to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "oprimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "batch_size: int = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fdae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/torch/optim/sgd.py:139: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
      "  if p.grad is not None:\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/torch/optim/optimizer.py:270: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
      "  if p.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss value: 1.61245596408844\n",
      "val loss value: 1.174818992614746\n",
      "val loss value: 0.9639116525650024\n",
      "val loss value: 0.8213350176811218\n",
      "val loss value: 0.714693009853363\n",
      "val loss value: 0.6246038675308228\n",
      "val loss value: 0.5309968590736389\n",
      "val loss value: 0.4981347322463989\n",
      "val loss value: 0.4408875107765198\n",
      "val loss value: 0.4023697078227997\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs: int = 10\n",
    "\n",
    "X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    indexes: np.ndarray = np.random.permutation(TRAIN_SIZE)\n",
    "    X_train, y_train = X_train[indexes], y_train[indexes]\n",
    "\n",
    "    net.train()\n",
    "    for i in range(0, TRAIN_SIZE, batch_size):\n",
    "        oprimizer.zero_grad()\n",
    "        X_batch = X_train[i:i + batch_size].to(device)\n",
    "        y_batch = y_train[i:i + batch_size].to(device)\n",
    "        y_pred = net(X_batch)\n",
    "        loss_value = loss(y_pred, y_batch)\n",
    "        loss_value.backward()\n",
    "        oprimizer.step()\n",
    "        oprimizer.zero_grad()\n",
    "        # print(f\"train loss value: {loss_value.cpu().item()}\")\n",
    "\n",
    "    net.eval()\n",
    "    y_pred = net(X_val)\n",
    "    loss_value = loss(y_pred, y_val)\n",
    "    print(f\"val loss value: {loss_value.cpu().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa27df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the exact values:\n",
    "x = torch.rand(3, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd0671e-f870-4ab0-bef0-633c2f519fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4106,  0.1715],\n",
       "         [-0.3810,  1.6808]],\n",
       "\n",
       "        [[-1.3260,  0.7506],\n",
       "         [-0.5303, -1.1750]],\n",
       "\n",
       "        [[ 1.3157, -1.3224],\n",
       "         [-0.5988,  1.0043]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomBatchNorm(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf03565-de9e-4809-8399-6316d537d5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4106,  0.1715],\n",
       "         [-0.3810,  1.6808]],\n",
       "\n",
       "        [[-1.3260,  0.7506],\n",
       "         [-0.5303, -1.1750]],\n",
       "\n",
       "        [[ 1.3157, -1.3224],\n",
       "         [-0.5988,  1.0043]]], grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BatchNorm1d(2)(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
