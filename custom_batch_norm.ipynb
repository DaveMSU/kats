{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee5de119-d09a-41d7-9e95-5deac33f5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "N = 1024 * 16\n",
    "VAL_SIZE = 512\n",
    "TRAIN_SIZE = N - VAL_SIZE\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "class CustomBatchNorm(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_features: int,\n",
    "            eps: float = 1e-05,\n",
    "            momentum: tp.Optional[float] = 0.1,\n",
    "            affine: bool = True,\n",
    "            track_running_stats: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._num_features: int = num_features\n",
    "        self._eps: float = eps\n",
    "        self._momentum: float = momentum\n",
    "        self._params: tp.Dict[str, torch.nn.Parameter] = torch.nn.ParameterDict(\n",
    "            {\n",
    "                \"weights\": torch.nn.Parameter(\n",
    "                    torch.ones(num_features),\n",
    "                    requires_grad=affine,\n",
    "                ),\n",
    "                \"bias\": torch.nn.Parameter(\n",
    "                    torch.zeros(num_features),\n",
    "                    requires_grad=affine\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        self._track_running_stats: bool = track_running_stats\n",
    "        self._running_stats: tp.Optional[\n",
    "            tp.Dict[\n",
    "                str,\n",
    "                tp.Union[torch.Tensor, int]\n",
    "            ]\n",
    "        ] = {\n",
    "            \"mean\": torch.zeros(num_features),\n",
    "            \"var\": torch.zeros(num_features),\n",
    "            \"count\": 0,\n",
    "        } if track_running_stats else None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_dim_order: tp.Tuple[int] = tuple(range(x.ndim))\n",
    "        dims_to_be_reduced: tp.Tuple[int] = x_dim_order[:1] + x_dim_order[2:]\n",
    "        batch_mean: torch.Tensor = x.mean(\n",
    "            dim=dims_to_be_reduced,\n",
    "            keepdim=True,\n",
    "        )\n",
    "        batch_var: torch.Tensor = x.var(\n",
    "            dim=dims_to_be_reduced,\n",
    "            correction=0,\n",
    "            keepdim=True,\n",
    "        )\n",
    "        if self.training and self._track_running_stats:\n",
    "            correction: float = x.shape[0] / max(x.shape[0] - 1, 1)\n",
    "            beta: float\n",
    "            if self._momentum is None:\n",
    "                beta = x.shape[0] / (self._running_stats[\"count\"] + x.shape[0])\n",
    "            else:\n",
    "                beta = self._momentum\n",
    "            self._running_stats[\"mean\"] += beta * (batch_mean.view(-1) - self._running_stats[\"mean\"])\n",
    "            self._running_stats[\"var\"] += beta * (correction * batch_var.view(-1) - self._running_stats[\"var\"])\n",
    "            self._running_stats[\"count\"] += x.shape[0]\n",
    "\n",
    "        dims_to_be_unreduced = (1, -1) + (1,) * (x.ndim - 2)\n",
    "        shift: torch.Tensor\n",
    "        scale: torch.Tensor\n",
    "        if self.training or (not self._track_running_stats):\n",
    "            shift, scale = batch_mean, (batch_var + self._eps) ** 0.5\n",
    "        else:\n",
    "            shift = self._running_stats[\"mean\"].view(dims_to_be_unreduced)\n",
    "            scale = (self._running_stats[\"var\"].view(dims_to_be_unreduced) + self._eps) ** 0.5\n",
    "\n",
    "        x_normed: torch.Tensor = (x - shift) / scale\n",
    "        weights = self._params[\"weights\"].view(dims_to_be_unreduced)\n",
    "        bias = self._params[\"bias\"].view(dims_to_be_unreduced)\n",
    "        return x_normed * weights + bias\n",
    "\n",
    "\n",
    "mnist = MNIST(\"./\", download=True)\n",
    "X: torch.Tensor = mnist.data.view(-1, 1, 28, 28)[:N] / 255.\n",
    "y: torch.Tensor = mnist.targets[:N]\n",
    "\n",
    "X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "X_val, y_val = X[TRAIN_SIZE:], y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1009f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device: torch.device = torch.device(\"cpu\")\n",
    "\n",
    "net: torch.nn.Module = torch.nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            (\n",
    "                'bn_test_0',\n",
    "                # torch.nn.BatchNorm2d(\n",
    "                CustomBatchNorm(\n",
    "                    num_features=1,\n",
    "                    eps=0.00001,\n",
    "                    momentum=0.1,\n",
    "                    affine=True,\n",
    "                    track_running_stats=True,\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                'conv_0',\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=1,\n",
    "                    out_channels=3,\n",
    "                    kernel_size=(3, 3),\n",
    "                    stride=(1, 1),\n",
    "                    padding=(0, 0),\n",
    "                    dilation=(1, 1),\n",
    "                    groups=1,\n",
    "                    bias=True,\n",
    "                )\n",
    "            ),\n",
    "            ('bn_test_1', CustomBatchNorm(3)),\n",
    "            # ('bn_test_1', torch.nn.BatchNorm2d(3)),\n",
    "            (\n",
    "                'act_1',\n",
    "                torch.nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            (\n",
    "                'pooling_2',\n",
    "                torch.nn.MaxPool2d(\n",
    "                    kernel_size=(4, 4),\n",
    "                    stride=(4, 4),\n",
    "                    padding=(0, 0),\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                'flatten_3',\n",
    "                Flatten()\n",
    "            ),\n",
    "            (\n",
    "                'fc_4',\n",
    "                torch.nn.Linear(\n",
    "                    in_features=3*6*6,\n",
    "                    out_features=10,\n",
    "                    bias=True,\n",
    "                )\n",
    "            ),\n",
    "            ('bn_test_2', CustomBatchNorm(10)),\n",
    "            # ('bn_test_2', torch.nn.BatchNorm1d(10)),\n",
    "            (\n",
    "                'act_5',\n",
    "                torch.nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            (\n",
    "                'fc_6',\n",
    "                torch.nn.Linear(10, 10)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ").to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "oprimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "batch_size: int = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8fdae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss value: 1.7054740190505981\n",
      "val loss value: 1.3781808614730835\n",
      "val loss value: 1.1435519456863403\n",
      "val loss value: 0.944825291633606\n",
      "val loss value: 0.7943838834762573\n",
      "val loss value: 0.657880961894989\n",
      "val loss value: 0.5529645681381226\n",
      "val loss value: 0.4810158312320709\n",
      "val loss value: 0.4336111843585968\n",
      "val loss value: 0.3929685652256012\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs: int = 10\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    indexes: np.ndarray = np.random.permutation(TRAIN_SIZE)\n",
    "    X_train, y_train = X_train[indexes], y_train[indexes]\n",
    "\n",
    "    net.train()\n",
    "    for i in range(0, TRAIN_SIZE, batch_size):\n",
    "        oprimizer.zero_grad()\n",
    "        X_batch = X_train[i:i + batch_size].to(device)\n",
    "        y_batch = y_train[i:i + batch_size].to(device)\n",
    "        y_pred = net(X_batch)\n",
    "        loss_value = loss(y_pred, y_batch)\n",
    "        loss_value.backward()\n",
    "        oprimizer.step()\n",
    "        oprimizer.zero_grad()\n",
    "        # print(f\"train loss value: {loss_value.cpu().item()}\")\n",
    "\n",
    "    # if epoch % 10 == 0:\n",
    "    net.eval()\n",
    "    y_pred = net(X_val)\n",
    "    loss_value = loss(y_pred, y_val)\n",
    "    print(f\"val loss value: {loss_value.cpu().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323080c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "609f937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the exact values:\n",
    "x = torch.rand(3, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdd0671e-f870-4ab0-bef0-633c2f519fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3376,  0.3614],\n",
       "         [-1.4641,  0.3514]],\n",
       "\n",
       "        [[ 1.9223, -0.1592],\n",
       "         [ 0.5904,  1.5894]],\n",
       "\n",
       "        [[-0.4256, -1.3613],\n",
       "         [-0.1554, -0.9117]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomBatchNorm(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bf03565-de9e-4809-8399-6316d537d5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3376,  0.3614],\n",
       "         [-1.4641,  0.3514]],\n",
       "\n",
       "        [[ 1.9223, -0.1592],\n",
       "         [ 0.5904,  1.5894]],\n",
       "\n",
       "        [[-0.4256, -1.3613],\n",
       "         [-0.1554, -0.9117]]], grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BatchNorm1d(2)(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
